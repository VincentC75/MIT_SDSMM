---
title: "Probability"
author: "Vincent Courtois"
date: "14/07/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## MIT Statistics and Data Science MicroMasters
## Probability

Notes

$Var(X) = E[X^2] - (E[X])^2$  
$cov(\theta,X)=E[\theta.X]-E[\theta].E[X]$  

Var(A|B) = Var(A) + Var(B) + cov(A,B)

Law of iterated expectations:  
$E[X] = E[E[X|\theta]]$  
$Var(X) = E[Var(X|\theta)] + Var(E[X|\theta])$  


Linear Least Mean Square Estimator:  
$\hat{\theta}_{LLMS} = E[\theta] + \frac{cov(\theta,X)}{Var(X)}(X-E[X])$  

Weak Law of Large Numbers:  
$\frac{X_1+...+X_n}{n} \to E[X], X_1,...,X_n i.i.d$

Markov inequality:  
if $X \ge 0$ and $a>0$, then $P(X \ge A) \le \frac{E[X]}{a}$

Chebyshev inequality:  
X mean $\mu$ and variance $\sigma^2$, $P(|X-\mu| \ge c) \le \frac{\sigma^2}{c^2}$