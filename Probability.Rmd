---
title: "Probability"
author: "Vincent Courtois"
date: "14/07/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## MIT Statistics and Data Science MicroMasters
## Probability

Notes

$$Var(X) = E[X^2] - (E[X])^2$$

$$cov(\theta,X)=E[\theta.X]-E[\theta].E[X]$$  

$$Var(A|B) = Var(A) + Var(B) + cov(A,B)$$


Linear combination
$$E[aX+b] = aE[X]+b$$
$$\sigma(aX+b) = |a|\sigma(X)$$
$$Var(aX+b) = a^2Var(X)$$

The four versions of Baye's Rule:

* $\Theta$ discrete, X discrete  
  $$p_{\Theta|X}(\theta|x) = \frac{p_\Theta(\theta)p_{X|\Theta}(x|\theta)}{\sum_{\theta'} p_\Theta(\theta')p_{X|\Theta}(x|\theta')}$$
* $\Theta$ discrete, X continuous
  $$p_{\Theta|X}(\theta|x) = \frac{p_\Theta(\theta)f_{X|\Theta}(x|\theta)}{\sum_{\theta'} p_\Theta(\theta')f_{X|\Theta}(x|\theta')}$$
* $\Theta$ continuous, X discrete
  $$f_{\Theta|X}(\theta|x) = \frac{f_\Theta(\theta)p_{X|\Theta}(x|\theta)}{\int f_\Theta(\theta')p_{X|\Theta}(x|\theta')d\theta'}$$
* $\Theta$ continuous, X continuous
  $$f_{\Theta|X}(\theta|x) = \frac{f_\Theta(\theta)f_{X|\Theta}(x|\theta)}{\int f_\Theta(\theta')f_{X|\Theta}(x|\theta')d\theta'}$$


**Law of total probability**: S sample space divided in disjoint S1 and S2 $$P(A) = P(A|S1)P(S1)+P(A|S2)P(S2)$$
**Law of iterated expectations**: $$E[X] = E[E[X|\theta]]$$  
**Law of total variance**: $$Var(X) = E[Var(X|\theta)] + Var(E[X|\theta])$$
Linear Least Mean Square Estimator: $$\hat{\theta}_{LLMS} = E[\theta] + \frac{cov(\theta,X)}{Var(X)}(X-E[X])$$  

Weak Law of Large Numbers: $$\frac{X_1+...+X_n}{n} \to E[X]$$, $X_1,...,X_n i.i.d$

Markov inequality:  
if $X \ge 0$ and $a>0$, then $$P(X \ge A) \le \frac{E[X]}{a}$$

Chebyshev inequality:  
X mean $\mu$ and variance $\sigma^2$, $$P(|X-\mu| \ge c) \le \frac{\sigma^2}{c^2}$$

Central Limit Theorem

$$ \sqrt{n} \frac{ \overline{X_n} - \mu} {\sigma} \longrightarrow_{n \to \infty} N(0,1) $$
$$ \sqrt{n} (\overline{X_n} - \mu) \longrightarrow_{n \to \infty} N(0,\sigma^2) $$
$$ \overline{X_n} = \frac{  \sum_{i=1}^{n} X_{i} }{n} \sim N(\mu,\frac{\sigma^2}{n})$$ 
$$ \frac{ S_n - n? \mu} {\sqrt{n} \sigma } \longrightarrow_{n \to \infty} N(0,1) $$


Jensen's inequality:
if g is a convex function, $$g(E[X]) \le E[g(X)]$$

Maximum Likelihood Estimation (MLE): Pick $\theta$ that "makes data most likely".
$$\hat{\theta}_{ML} = \underset{\theta}{\operatorname{arg max}} p_X(x;\theta)$$

Distribution|pmf/pdf|cdf|mean|variance|
:-----------|:---|:---|:--------|:----|
Bernouilli|$f_p(k)=p^k (1-p)^{1-k}$||$p$|$p(1-p)$
Geometric|$f_p(k)=p(1-p)^{k-1}$|$1-(1-p)^k$|$\frac{1}{p}$|$\frac{1-p}{p^2}$
Poisson|$f_{\lambda}(k)=\frac{\lambda^ke^{-\lambda}}{k!}$||$\lambda$|$\lambda$
Exponential|$f_{\lambda}(x)=\lambda e^{-\lambda x}$|$1-e^{-\lambda x}$|$\frac{1}{\lambda}$|$\frac{1}{\lambda^2}$
Gaussian/Normal|$f_{(\mu,\sigma^2)}(x) = \frac{1}{\sigma \sqrt{2 \pi} } e^{-\frac{(x - \mu)^2}{2 \sigma^2} }$||$\mu$|$\sigma^2$



